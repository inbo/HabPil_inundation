{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "respected-companion",
   "metadata": {},
   "source": [
    "# Timeseries Sentinel 2 from openEO\n",
    "In this Notebook, we will extract time series of Sentinel-2 NDVI from a Data Cube for the inundation case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20b78b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import openeo\n",
    "from openeo.rest.job import RESTJob\n",
    "from openeo.rest.conversions import timeseries_json_to_pandas\n",
    "import shapely.geometry\n",
    "import scipy.signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222532e0",
   "metadata": {},
   "source": [
    "# Get the data from the backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17be01d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeoJSON Features: [{'type': 'Feature', 'properties': {'id': 1}, 'geometry': {'type': 'MultiPolygon', 'coordinates': [[[[4.968710486638257, 51.00869219207143], [4.980305670916424, 51.00784563198833], [4.979613659415014, 51.00357796037619], [4.973508463494545, 51.00378616074288], [4.968512914917515, 51.00519269175937], [4.968710486638257, 51.00869219207143]]]]}}]\n",
      "Polygon Geometry: MULTIPOLYGON (((4.968710486638257 51.00869219207143, 4.980305670916424 51.00784563198833, 4.979613659415014 51.00357796037619, 4.973508463494545 51.00378616074288, 4.968512914917515 51.00519269175937, 4.968710486638257 51.00869219207143)))\n",
      "Bounds: (4.968512914917515, 51.00357796037619, 4.980305670916424, 51.00869219207143)\n"
     ]
    }
   ],
   "source": [
    "# Open the GeoJSON file and read the features\n",
    "with open(\"../input/test_site_demervallei_WGS84_v2.geojson\") as f:\n",
    "    features = json.load(f)[\"features\"]\n",
    "\n",
    "print(\"GeoJSON Features:\", features)\n",
    "\n",
    "# Assuming a single polygon in the GeoJSON file\n",
    "geometry = shapely.geometry.shape(features[0][\"geometry\"])  # Extract the geometry of the first feature\n",
    "\n",
    "# Get the bounds of the polygon (minx, miny, maxx, maxy)\n",
    "bounds = geometry.bounds\n",
    "\n",
    "print(\"Polygon Geometry:\", geometry)\n",
    "print(\"Bounds:\", bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb45b6a7-f139-4134-8866-98f16e6b9b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"2024-05-01\"\n",
    "end_date = \"2024-05-08\"\n",
    "bands = [ \"B08\", \"B11\", \"SCL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "vocational-moscow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated using refresh token.\n"
     ]
    }
   ],
   "source": [
    "con  = openeo.connect(\"https://openeo.vito.be\").authenticate_oidc(provider_id=\"egi\")\n",
    "bbox = {\"west\": geometry.bounds[0] , \"south\":geometry.bounds[1] , \"east\": geometry.bounds[2], \"north\": geometry.bounds[3], \"crs\": \"EPSG:4326\"}\n",
    "dates = (start_date, end_date)\n",
    "\n",
    "datacube = con.load_collection(\"SENTINEL2_L2A\", temporal_extent=dates, bands=bands, spatial_extent = bbox)\n",
    "\n",
    "# Extract band11\n",
    "band11 = datacube.band(\"B11\")\n",
    "\n",
    "# Calculate NDMI\n",
    "ndmi = datacube.ndvi(nir=\"B08\", red=\"B11\")\n",
    "\n",
    "# Extract the Scene Classification (SCL) layer\n",
    "classification = datacube.band(\"SCL\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a588ce4-f650-4990-b5d9-47550cc8afda",
   "metadata": {},
   "source": [
    "## Masking with a kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "clinical-upset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cloud mask using SCL values (4 and 5 are vegetated and non-vegetated)\n",
    "cloud_mask = ~((classification == 4) | (classification == 5))\n",
    "\n",
    "# Apply a Gaussian kernel to smooth the mask\n",
    "g = scipy.signal.windows.gaussian(11, std=1.5)  # 11x11 kernel with std=1.5\n",
    "kernel = np.outer(g, g)\n",
    "kernel = kernel / kernel.sum()  # Normalize kernel\n",
    "cloud_mask = cloud_mask.apply_kernel(kernel)\n",
    "\n",
    "# Threshold the smoothed mask\n",
    "cloud_mask = cloud_mask > 0.1  # Threshold to make it binary again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27886fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the mask to both Band 11 and NDMI\n",
    "masked_band11 = band11.mask(cloud_mask)\n",
    "masked_ndmi = ndmi.mask(cloud_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917afa34-5b19-44ce-b84e-fd837a724a1b",
   "metadata": {},
   "source": [
    "## Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f0c118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00 Job 'j-2501170806154bb29cf56874dd8e40be': send 'start'\n",
      "0:00:16 Job 'j-2501170806154bb29cf56874dd8e40be': queued (progress 0%)\n",
      "0:00:21 Job 'j-2501170806154bb29cf56874dd8e40be': queued (progress 0%)\n",
      "0:00:27 Job 'j-2501170806154bb29cf56874dd8e40be': queued (progress 0%)\n",
      "0:00:35 Job 'j-2501170806154bb29cf56874dd8e40be': queued (progress 0%)\n",
      "0:00:45 Job 'j-2501170806154bb29cf56874dd8e40be': queued (progress 0%)\n",
      "0:00:58 Job 'j-2501170806154bb29cf56874dd8e40be': queued (progress 0%)\n",
      "0:01:13 Job 'j-2501170806154bb29cf56874dd8e40be': queued (progress 0%)\n",
      "0:01:32 Job 'j-2501170806154bb29cf56874dd8e40be': queued (progress 0%)\n",
      "0:01:56 Job 'j-2501170806154bb29cf56874dd8e40be': queued (progress 0%)\n",
      "0:02:26 Job 'j-2501170806154bb29cf56874dd8e40be': queued (progress 0%)\n",
      "0:03:04 Job 'j-2501170806154bb29cf56874dd8e40be': queued (progress 0%)\n",
      "0:03:50 Job 'j-2501170806154bb29cf56874dd8e40be': queued (progress 0%)\n",
      "0:04:49 Job 'j-2501170806154bb29cf56874dd8e40be': queued (progress 0%)\n",
      "0:05:49 Job 'j-2501170806154bb29cf56874dd8e40be': running (progress N/A)\n",
      "0:06:49 Job 'j-2501170806154bb29cf56874dd8e40be': finished (progress 100%)\n",
      "Multiband GeoTIFF file saved to: [WindowsPath('../output/band11/openEO_2024-05-01Z.tif'), WindowsPath('../output/band11/openEO_2024-05-04Z.tif'), WindowsPath('../output/band11/openEO_2024-05-06Z.tif'), WindowsPath('../output/band11/job-results.json')]\n"
     ]
    }
   ],
   "source": [
    "# Save all time slices of Band 11 as individual GeoTiffs\n",
    "job = masked_band11.save_result(\n",
    "    format=\"GTiff\",\n",
    "    options={\"tiled\": True, \"bands_dimension\": \"t\"}  \n",
    ")\n",
    "\n",
    "# Execute the batch job\n",
    "job = job.execute_batch()\n",
    "\n",
    "# Download the single multiband GeoTIFF file\n",
    "job_results = job.get_results()\n",
    "result_files = job_results.download_files(target=\"../output/band11\")\n",
    "\n",
    "print(\"GeoTIFF files saved to:\", result_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "021e9b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00 Job 'j-25011708454640f0af1765162691d5fc': send 'start'\n",
      "0:00:15 Job 'j-25011708454640f0af1765162691d5fc': queued (progress 0%)\n",
      "0:00:20 Job 'j-25011708454640f0af1765162691d5fc': queued (progress 0%)\n",
      "0:00:27 Job 'j-25011708454640f0af1765162691d5fc': queued (progress 0%)\n",
      "0:00:35 Job 'j-25011708454640f0af1765162691d5fc': queued (progress 0%)\n",
      "0:00:45 Job 'j-25011708454640f0af1765162691d5fc': queued (progress 0%)\n",
      "0:00:57 Job 'j-25011708454640f0af1765162691d5fc': queued (progress 0%)\n",
      "0:01:12 Job 'j-25011708454640f0af1765162691d5fc': queued (progress 0%)\n",
      "0:01:32 Job 'j-25011708454640f0af1765162691d5fc': queued (progress 0%)\n",
      "0:01:56 Job 'j-25011708454640f0af1765162691d5fc': running (progress N/A)\n",
      "0:02:26 Job 'j-25011708454640f0af1765162691d5fc': running (progress N/A)\n",
      "0:03:03 Job 'j-25011708454640f0af1765162691d5fc': finished (progress 100%)\n",
      "Multiband GeoTIFF file saved to: [WindowsPath('../output/ndmi/openEO_2024-05-01Z.tif'), WindowsPath('../output/ndmi/openEO_2024-05-04Z.tif'), WindowsPath('../output/ndmi/openEO_2024-05-06Z.tif'), WindowsPath('../output/ndmi/job-results.json')]\n"
     ]
    }
   ],
   "source": [
    "# Save all time slices of Band 11 as a multiband GeoTIFF\n",
    "job = ndmi.save_result(\n",
    "    format=\"GTiff\",\n",
    "    options={\"tiled\": True, \"bands_dimension\": \"t\"}  # Combine all time steps into bands\n",
    ")\n",
    "\n",
    "# Execute the batch job\n",
    "job = job.execute_batch()\n",
    "\n",
    "# Download the single multiband GeoTIFF file\n",
    "job_results = job.get_results()\n",
    "result_files = job_results.download_files(target=\"../output/ndmi\")\n",
    "\n",
    "print(\"Multiband GeoTIFF file saved to:\", result_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7add2a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00 Job 'j-2501160936344e539d163f22853eb6c9': send 'start'\n",
      "0:02:13 Job 'j-2501160936344e539d163f22853eb6c9': created (progress 0%)\n",
      "0:02:18 Job 'j-2501160936344e539d163f22853eb6c9': queued (progress 0%)\n",
      "0:02:24 Job 'j-2501160936344e539d163f22853eb6c9': queued (progress 0%)\n",
      "0:02:32 Job 'j-2501160936344e539d163f22853eb6c9': queued (progress 0%)\n",
      "0:02:42 Job 'j-2501160936344e539d163f22853eb6c9': queued (progress 0%)\n",
      "0:02:55 Job 'j-2501160936344e539d163f22853eb6c9': finished (progress 100%)\n"
     ]
    }
   ],
   "source": [
    "# Save the SCL band as a GeoTIFF file\n",
    "job = classification.save_result(format=\"GTiff\", options={\"tiled\": True})\n",
    "\n",
    "# Execute the batch job to process the data and generate the output\n",
    "job = job.execute_batch()\n",
    "\n",
    "# Download the resulting GeoTIFF file\n",
    "job_results = job.get_results()\n",
    "result_files = job_results.download_files(target=\"../output/scl_output\")\n",
    "\n",
    "print(\"SCL GeoTIFF saved to:\", result_files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inundation-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
